GPT_CONFIG_124M = {
    "vocab_size": 50257,
    "context_length": 1024,
    "emb_dim": 768,         #embedding dimension
    "n_heads": 12,          #Number of Attention Heads
    "n_layers": 12,         
    "drop_rate": 0.1,       #DropoutRate
    "qkv_bias": False       #Query Key Value Bias


}